import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import plotly.express as px
import plotly.graph_objects as go

def preparar_datos(df):
    """
    Prepara los datos para el an√°lisis, separando variables num√©ricas y no num√©ricas.
    """
    if df is not None:
        st.write("### Selecci√≥n de variables")
        
        # Separar columnas num√©ricas y no num√©ricas
        columnas_numericas = df.select_dtypes(include=np.number).columns.tolist()
        columnas_no_numericas = df.select_dtypes(exclude=np.number).columns.tolist()
        
        # Verificar si hay columnas num√©ricas
        if not columnas_numericas:
            st.error("No hay columnas num√©ricas en el dataset")
            return None, None, None, None
            
        # Mostrar informaci√≥n sobre las columnas
        st.info(f"Columnas num√©ricas disponibles: {', '.join(columnas_numericas)}")
        if columnas_no_numericas:
            st.warning(f"Columnas no num√©ricas (no se usar√°n para el modelo): {', '.join(columnas_no_numericas)}")
        
        # Seleccionar variable objetivo (solo num√©rica)
        variable_objetivo = st.selectbox(
            "Selecciona la variable NUM√âRICA objetivo (y):",
            options=columnas_numericas
        )
        
        # Seleccionar variables predictoras (solo num√©ricas)
        variables_predictoras = st.multiselect(
            "Selecciona variables predictoras NUM√âRICAS (X):",
            options=[col for col in columnas_numericas if col != variable_objetivo]
        )
        
        if variables_predictoras:
            # Verificar el n√∫mero de registros disponibles
            total_registros = len(df)
            
            if total_registros < 3:
                st.error("Se necesitan al menos 3 registros para entrenar el modelo.")
                return None, None, None, None
            
            # Ajustar valores del slider seg√∫n cantidad de datos
            min_registros = min(3, total_registros)
            valor_default = min(100, total_registros)
            
            # N√∫mero de registros a usar
            num_registros = st.slider(
                "Selecciona la cantidad de registros a utilizar",
                min_value=min_registros,
                max_value=total_registros,
                value=valor_default
            )
            
            # Preparar los datos (solo columnas num√©ricas)
            X = df[variables_predictoras][:num_registros]
            y = df[variable_objetivo][:num_registros]
            
            # Verificar que no haya valores nulos
            nulos_X = X.isnull().sum()
            nulos_y = y.isnull().sum()
            
            if nulos_X.any() or nulos_y > 0:
                st.warning("‚ö†Ô∏è Se detectaron valores nulos:")
                if nulos_X.any():
                    st.write("Variables predictoras con nulos:")
                    for col, nulos in nulos_X[nulos_X > 0].items():
                        st.write(f"- {col}: {nulos} valores nulos")
                if nulos_y > 0:
                    st.write(f"Variable objetivo '{variable_objetivo}': {nulos_y} valores nulos")
                
                # Opci√≥n para manejar nulos
                manejo_nulos = st.radio(
                    "¬øC√≥mo deseas manejar los valores nulos?",
                    ["Eliminar filas con nulos", "Rellenar con la media", "Mantener los nulos"]
                )
                
                if manejo_nulos == "Eliminar filas con nulos":
                    mask = X.notnull().all(axis=1) & y.notnull()
                    X = X[mask]
                    y = y[mask]
                    st.info(f"Se eliminaron {(~mask).sum()} filas con valores nulos")
                elif manejo_nulos == "Rellenar con la media":
                    X = X.fillna(X.mean())
                    y = y.fillna(y.mean())
                    st.info("Se rellenaron los valores nulos con la media")
            
            # Verificar datos finales
            if len(X) < 3:
                st.error("No hay suficientes datos v√°lidos despu√©s de procesar los nulos")
                return None, None, None, None
                
            # Mostrar resumen final
            st.success(f"""
            ‚úÖ Datos preparados exitosamente:
            - Registros seleccionados: {len(X)}
            - Variables predictoras: {len(variables_predictoras)}
            - Variable objetivo: {variable_objetivo}
            """)
            
            return X, y, variables_predictoras, variable_objetivo
    
    return None, None, None, None




def generar_reporte_completo(X, y, variables_predictoras, variable_objetivo):
    """
    Versi√≥n simplificada del reporte con an√°lisis esencial y visualizaciones claras
    """
    try:
        st.header("üìä Reporte Anal√≠tico R√°pido")
        
        # 1. An√°lisis estad√≠stico b√°sico
        st.subheader("1. Estad√≠sticas Clave")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Muestra Total", len(X))
            st.write(f"Variables Predictoras: {len(variables_predictoras)}")
            
        with col2:
            st.metric(f"Media de {variable_objetivo}", f"{y.mean():.2f}")
            st.metric(f"Rango de {variable_objetivo}", f"{y.min():.2f} - {y.max():.2f}")
        
        # 2. Correlaciones
        st.subheader("2. Correlaciones Principales")
        numeric_df = X.select_dtypes(include=np.number).join(y)
        corr_matrix = numeric_df.corr().round(2)
        fig = px.imshow(corr_matrix, text_auto=True)
        st.plotly_chart(fig, use_container_width=True)
        
        # 3. Modelo r√°pido
        st.subheader("3. Modelo Predictivo")
        modelo = entrenar_modelo_simplificado(X, y)
        
        if modelo:
            # 4. Importancia de variables
            st.subheader("4. Variables m√°s Importantes")
            importancia = obtener_importancia_variables(modelo, X)
            st.bar_chart(importancia.set_index('Variable'))
            
            # 5. Conclusiones clave
            st.subheader("5. Conclusiones")
            r2 = modelo.r2 if hasattr(modelo, 'r2') else 0
            conclusiones = [
                f"üß† El modelo explica el {r2*100:.1f}% de la variabilidad ({variable_objetivo})",
                f"üìå Variable m√°s importante: {importancia.iloc[0]['Variable']}",
                "üí° Recomendaci√≥n: " + ("Mejorar con m√°s datos" if r2 < 0.7 else "Modelo confiable")
            ]
            st.success("\n\n".join(conclusiones))
            
        return True
        
    except Exception as e:
        st.error(f"Error generando reporte: {str(e)}")
        return False

# Funciones auxiliares simplificadas
def entrenar_modelo_simplificado(X, y):
    try:
        # Identificar columnas num√©ricas
        columnas_numericas = X.select_dtypes(include=['int64', 'float64']).columns
        
        if len(columnas_numericas) == 0:
            st.warning("No hay variables num√©ricas para entrenar el modelo")
            return None
            
        # Usar solo las columnas num√©ricas
        X_num = X[columnas_numericas]
        
        # Verificar que la variable objetivo sea num√©rica
        if not pd.to_numeric(y, errors='coerce').notnull().all():
            st.warning("La variable objetivo debe ser num√©rica")
            return None
            
        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(X_num, y, test_size=0.2)
        
        # Entrenar modelo
        modelo = RandomForestRegressor().fit(X_train, y_train)
        y_pred = modelo.predict(X_test)
        
        # Calcular m√©tricas
        modelo.mse = mean_squared_error(y_test, y_pred)
        modelo.r2 = r2_score(y_test, y_pred)
        
        # Guardar las columnas usadas
        modelo.columnas_usadas = columnas_numericas
        
        # Mostrar informaci√≥n
        st.info(f"Variables num√©ricas utilizadas: {', '.join(columnas_numericas)}")
        
        return modelo
        
    except Exception as e:
        st.warning(f"No se pudo entrenar el modelo: {str(e)}")
        return None
    
def obtener_importancia_variables(modelo, X):
    # Usar solo las columnas que se usaron en el entrenamiento
    return pd.DataFrame({
        'Variable': modelo.columnas_usadas,
        'Importancia': modelo.feature_importances_
    }).sort_values('Importancia', ascending=False).head(5)